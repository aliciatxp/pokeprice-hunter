{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12caa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website loaded.\n",
      "Page refreshed.\n",
      "\n",
      "Processing main nav item 3\n",
      "  Clicking on: SV10 / ロケット団の栄光\n",
      "    Scraping page 1\n",
      "    Scraping page 2\n",
      "    Scraping page 3\n",
      "    Scraping page 4\n",
      "    Scraping page 5\n",
      "    Scraping page 6\n",
      "    Scraping page 7\n",
      "    Scraping page 8\n",
      "    Scraping page 9\n",
      "    Scraping page 10\n",
      "    No more pages.\n",
      "  Clicking on: SV9a / 熱風のアリーナ\n",
      "    Scraping page 1\n",
      "    Scraping page 2\n",
      "    Scraping page 3\n",
      "    Scraping page 4\n",
      "    Scraping page 5\n",
      "    Scraping page 6\n",
      "    No more pages.\n",
      "  Clicking on: SV9 / バトルパートナーズ\n",
      "    Scraping page 1\n",
      "    Scraping page 2\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless=new')\n",
    "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "chrome_options.add_argument('--disable-popup-blocking')\n",
    "chrome_options.add_argument('--window-size=1920,1080')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "driver.get(\"https://torecacamp-pokemon.com/\")\n",
    "print(\"Website loaded.\")\n",
    "\n",
    "# handle pop up\n",
    "time.sleep(4)\n",
    "try:\n",
    "    # close popup if it exists\n",
    "    close_button = driver.find_element(By.CSS_SELECTOR, \".popup-close-button\")\n",
    "    close_button.click()\n",
    "    print(\"Popup closed.\")\n",
    "except:\n",
    "    driver.refresh()\n",
    "    time.sleep(3)\n",
    "    print(\"Page refreshed.\")\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"torecacamp_{current_datetime}.csv\"\n",
    "\n",
    "csv_file = open(csv_filename, 'w', newline='', encoding='utf-8-sig')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Category', 'Subcategory', 'Card Name', 'Price', 'URL'])\n",
    "\n",
    "all_data = []\n",
    "\n",
    "try:\n",
    "    # find all main navigation items\n",
    "    nav_items = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, \"/html/body/div[3]/section/nav/div/div/ul/li\"))\n",
    "    )\n",
    "    \n",
    "    # only get items 3 to 8 (Scarlet and violet to Legend)\n",
    "    for i in range(2, 8):\n",
    "        if i >= len(nav_items):\n",
    "            print(f\"Nav item {i+1} doesn't exist. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing main nav item {i+1}\")\n",
    "\n",
    "        main_nav = nav_items[i]\n",
    "        ActionChains(driver).move_to_element(main_nav).perform()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # find all dropdown items for this nav\n",
    "        try:\n",
    "            dropdown_items = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, f\"/html/body/div[3]/section/nav/div/div/ul/li[{i+1}]/ul/li\"))\n",
    "            )\n",
    "            \n",
    "            # only second dropdown item (expansion packs)\n",
    "            if len(dropdown_items) >= 2:\n",
    "                second_dropdown = dropdown_items[1]\n",
    "\n",
    "                ActionChains(driver).move_to_element(second_dropdown).perform()\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # et all sub-dropdown items\n",
    "                sub_dropdown_items = WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, f\"/html/body/div[3]/section/nav/div/div/ul/li[{i+1}]/ul/li[2]/ul/li\"))\n",
    "                )\n",
    "                \n",
    "                main_category = main_nav.text.strip()\n",
    "                subcategory = second_dropdown.text.strip()\n",
    "                \n",
    "                # process each sub-dropdown item\n",
    "                for j, sub_item in enumerate(sub_dropdown_items):\n",
    "                    try:\n",
    "                        link = sub_item.find_element(By.TAG_NAME, \"a\")\n",
    "                        link_url = link.get_attribute(\"href\")\n",
    "                        link_text = link.text.strip()\n",
    "                        \n",
    "                        print(f\"  Clicking on: {link_text}\")\n",
    "                        \n",
    "                        driver.execute_script(\"window.open(arguments[0]);\", link_url)\n",
    "\n",
    "                        driver.switch_to.window(driver.window_handles[-1])\n",
    "                        time.sleep(3)\n",
    "                        \n",
    "                        # scrape all pages of cards\n",
    "                        page_num = 1\n",
    "                        while True:\n",
    "                            print(f\"    Scraping page {page_num}\")\n",
    "\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CSS_SELECTOR, \".product-item__title\"))\n",
    "                            )\n",
    "\n",
    "                            cards = driver.find_elements(By.CSS_SELECTOR, \".product-item__title\")\n",
    "                            prices = driver.find_elements(By.CSS_SELECTOR, \".price-list span:not(.visually-hidden)\")\n",
    "                            \n",
    "                            # process each card\n",
    "                            for k in range(len(cards)):\n",
    "                                if k < len(prices):\n",
    "                                    card_name = cards[k].text.strip()\n",
    "                                    card_price = prices[k].text.strip()\n",
    "\n",
    "                                    csv_writer.writerow([main_category, subcategory, card_name, card_price, driver.current_url])\n",
    "                                    \n",
    "                                    # also keep in memory\n",
    "                                    all_data.append({\n",
    "                                        \"Category\": main_category,\n",
    "                                        \"Subcategory\": subcategory,\n",
    "                                        \"Card Name\": card_name,\n",
    "                                        \"Price\": card_price,\n",
    "                                        \"URL\": driver.current_url\n",
    "                                    })\n",
    "                            \n",
    "                            # check for next page\n",
    "                            try:\n",
    "                                next_button = WebDriverWait(driver, 5).until(\n",
    "                                    EC.presence_of_element_located((By.XPATH, \"//a[@rel='next']\"))\n",
    "                                )\n",
    "                                next_button.click()\n",
    "                                page_num += 1\n",
    "                                time.sleep(3)\n",
    "                            except:\n",
    "                                print(\"    No more pages.\")\n",
    "                                break\n",
    "\n",
    "                        driver.close()\n",
    "                        driver.switch_to.window(driver.window_handles[0])\n",
    "                        time.sleep(1)\n",
    "\n",
    "                        ActionChains(driver).move_to_element(main_nav).perform()\n",
    "                        time.sleep(1)\n",
    "\n",
    "                        dropdown_items = WebDriverWait(driver, 5).until(\n",
    "                            EC.presence_of_all_elements_located((By.XPATH, f\"/html/body/div[3]/section/nav/div/div/ul/li[{i+1}]/ul/li\"))\n",
    "                        )\n",
    "                        second_dropdown = dropdown_items[1]\n",
    "                        ActionChains(driver).move_to_element(second_dropdown).perform()\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"    Error processing sub-item {j+1}: {str(e)}\")\n",
    "                        if len(driver.window_handles) > 1:\n",
    "                            driver.close()\n",
    "                            driver.switch_to.window(driver.window_handles[0])\n",
    "            else:\n",
    "                print(f\"  No second dropdown item found for nav item {i+1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing dropdown for nav item {i+1}: {str(e)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in main navigation process: {str(e)}\")\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "driver.quit()\n",
    "print(f\"Scraping finished! Raw data saved to {csv_filename}\")\n",
    "\n",
    "df['Price'] = df['Price'].apply(lambda x: re.sub(r'[^\\d,¥]+', '', x))\n",
    "\n",
    "df_clean = df[['Card Name', 'Price']]\n",
    "\n",
    "# Define multiple patterns to handle different formats\n",
    "def extract_card_details(card_name):\n",
    "    # Pattern 1: Standard format with 【状態X】\n",
    "    pattern1 = re.compile(r'^【状態(?P<condition>[A-C][+-]?)】(?P<card_name>.+?)\\s+(?P<set>[A-Z0-9]+)\\s+(?P<card_number>\\d+/\\d+)(?:\\s+【(?P<letter>[^】]+)】)?(?:\\s+(?P<extra>.+))?$')\n",
    "    \n",
    "    # Pattern 2: Standard format without condition\n",
    "    pattern2 = re.compile(r'^(?P<card_name>.+?)\\s+(?P<set>[A-Z0-9]+)\\s+(?P<card_number>\\d+/\\d+)(?:\\s+【(?P<letter>[^】]+)】)?(?:\\s+(?P<extra>.+))?$')\n",
    "    \n",
    "    # Pattern 3: Format with \"状態X)\" instead of 【状態X】\n",
    "    pattern3 = re.compile(r'^状態(?P<condition>[A-C][+-]?)\\)(?P<card_name>.+?)\\s+(?P<set>[A-Z0-9]+)\\s+(?P<card_number>\\d+/\\d+)(?:\\s+(?P<extra>.+))?$')\n",
    "    \n",
    "    # Pattern 4: Format with 1ED at the end\n",
    "    pattern4 = re.compile(r'^【状態(?P<condition>[A-C][+-]?)】(?P<card_name>.+?)\\s+(?P<set>[A-Z0-9]+)\\s+(?P<card_number>\\d+/\\d+)(?:\\s+1ED)(?:\\s+(?P<extra>.+))?$')\n",
    "    \n",
    "    # Pattern 5: Format without condition but with 1ED\n",
    "    pattern5 = re.compile(r'^(?P<card_name>.+?)\\s+(?P<set>[A-Z0-9]+)\\s+(?P<card_number>\\d+/\\d+)(?:\\s+1ED)(?:\\s+(?P<extra>.+))?$')\n",
    "    \n",
    "    # Try each pattern\n",
    "    for pattern in [pattern1, pattern3, pattern4, pattern2, pattern5]:\n",
    "        match = pattern.match(card_name)\n",
    "        if match:\n",
    "            d = match.groupdict()\n",
    "            # Set default values for missing fields\n",
    "            condition = d.get('condition', 'A')  # Default to 'A' if not specified\n",
    "            letter = d.get('letter', None)\n",
    "            extra = d.get('extra', None)\n",
    "            \n",
    "            return pd.Series([\n",
    "                condition, \n",
    "                d['card_name'].strip(), \n",
    "                d['set'], \n",
    "                d['card_number'],\n",
    "                letter,\n",
    "                extra\n",
    "            ])\n",
    "    \n",
    "    # If no pattern matches, try a more lenient approach\n",
    "    # fallback for unusual formats\n",
    "    parts = card_name.split()\n",
    "    if len(parts) >= 3:\n",
    "        # Try to find the card number pattern (typically XXX/XXX)\n",
    "        for i, part in enumerate(parts):\n",
    "            if re.match(r'\\d+/\\d+', part):\n",
    "                # Found a card number\n",
    "                set_code = parts[i-1] if i > 0 else None\n",
    "                \n",
    "                # Check if there's a condition marker\n",
    "                condition = None\n",
    "                if card_name.startswith('【状態'):\n",
    "                    condition_match = re.match(r'【状態([A-C][+-]?)】', card_name)\n",
    "                    condition = condition_match.group(1) if condition_match else None\n",
    "                \n",
    "                # Everything before the set code (minus condition) is the card name\n",
    "                name_parts = parts[:i-1]\n",
    "                if condition and card_name.startswith('【状態'):\n",
    "                    # Remove the condition part from name\n",
    "                    full_name = ' '.join(name_parts)\n",
    "                    card_name_clean = re.sub(r'^【状態[A-C][+-]?】\\s*', '', full_name)\n",
    "                else:\n",
    "                    card_name_clean = ' '.join(name_parts)\n",
    "                \n",
    "                return pd.Series([\n",
    "                    condition if condition else 'A',\n",
    "                    card_name_clean.strip(),\n",
    "                    set_code,\n",
    "                    part,\n",
    "                    None,\n",
    "                    ' '.join(parts[i+1:]) if i+1 < len(parts) else None\n",
    "                ])\n",
    "    \n",
    "    # If all else fails, return None for all fields\n",
    "    return pd.Series([None, None, None, None, None, None])\n",
    "\n",
    "new_cols = df_clean['Card Name'].apply(extract_card_details)\n",
    "new_cols.columns = ['condition', 'card_name', 'set', 'card_number', 'letter', 'extra']\n",
    "\n",
    "df_expanded = pd.concat([df_clean, new_cols], axis=1)\n",
    "\n",
    "# Convert None to 'A' for condition where appropriate\n",
    "df_expanded['condition'] = df_expanded['condition'].fillna('A')\n",
    "\n",
    "df_expanded.to_csv(f\"clean_torecacamp_{current_datetime}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects-venv",
   "language": "python",
   "name": "projects-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
